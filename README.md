
# Micrograd

Projeto de um Micrograd, com as função de realizar uma retropropagação  automatica, construido totalmente a mão com base no video do Andrej Karpathy.


# Propagation backward

A “Propagation backward” é um algoritmo usado para melhorar as variáveis, deixando a previsão mais precisa. Esse processo ocorre após todo o processo da rede neural de gerar um valor, depois o compara com o resultado correto gerando uma perda, essa perda é propagada de volta, para melhorar as variáveis e diminuir a perda.
## Autor

- [Pablo Vinícius](https://github.com/PabloViniciusSS)




## Aprendizados

O objetivo é entender melhor como esse processo funciona na prática, para aprimorar as variáveis que são dinâmicas, através das derivadas que são encontradas a partir da perda do resultado encontrado comparado com cada variável existente na rede neural.
Essa perda é encontrada com o comparativo do resultado previsto pela rede e o resultado real.
E o processo é repetido até a previsão tenham uma ótima precisão

